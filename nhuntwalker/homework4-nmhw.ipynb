{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Debugging Homework"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Debugging the scipy script for optimization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "A script to compare different root-finding algorithms.\n",
      "\n",
      "This version of the script is buggy and does not execute. It is your task\n",
      "to find an fix these bugs.\n",
      "\n",
      "The output of the script sould look like:\n",
      "\n",
      "    Benching 1D root-finder optimizers from scipy.optimize:\n",
      "                brenth:   604678 total function calls\n",
      "                brentq:   594454 total function calls\n",
      "                ridder:   778394 total function calls\n",
      "                bisect:  2148380 total function calls\n",
      "\"\"\"\n",
      "from itertools import product\n",
      "\n",
      "import numpy as np\n",
      "from scipy import optimize\n",
      "\n",
      "FUNCTIONS = (np.tan,  # Dilating map\n",
      "             np.tanh, # Contracting map\n",
      "             lambda x: x**3 + 1e-4*x, # Almost null gradient at the root\n",
      "             lambda x: x+np.sin(2.0*x), # Non monotonous function\n",
      "             lambda x: 1.1*x+np.sin(4*x) # Function with several local maxima\n",
      "            )\n",
      "\n",
      "OPTIMIZERS = (optimize.brenth, optimize.brentq, optimize.ridder,\n",
      "              optimize.bisect)\n",
      "\n",
      "\n",
      "def apply_optimizer(optimizer, func, a, b):\n",
      "    \"\"\" Return the number of function calls given an root-finding optimizer, \n",
      "        a function and upper and lower bounds.\n",
      "    \"\"\"\n",
      "    return optimizer(func, a, b, full_output=True)[1].function_calls\n",
      "\n",
      "\n",
      "def bench_optimizer(optimizer, param_grid):\n",
      "    \"\"\" Find roots for all the functions, and upper and lower bounds\n",
      "        given and return the total number of function calls.\n",
      "    \"\"\"\n",
      "    return sum(apply_optimizer(optimizer, func, a, b)\n",
      "               for func, a, b in param_grid)\n",
      "\n",
      "\n",
      "def compare_optimizers(optimizers):\n",
      "    \"\"\" Compare all the optimizers given on a grid of a few different\n",
      "        functions all admitting a single root in zero and a upper and\n",
      "        lower bounds.\n",
      "    \"\"\"\n",
      "    random_a = -1.3 + np.random.random(size=100)\n",
      "    random_b =   .3 + np.random.random(size=100)\n",
      "    print \"Benching 1D root-finder optimizers from scipy.optimize:\"\n",
      "    for optimizer in OPTIMIZERS:\n",
      "        param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "        print '% 20s: % 8i total function calls' % (\n",
      "                    optimizer.__name__, \n",
      "                    bench_optimizer(optimizer, param_grid)\n",
      "                )\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    compare_optimizers(OPTIMIZERS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Benching 1D root-finder optimizers from scipy.optimize:\n",
        "              brenth:   602314 total function calls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              brentq:   591708 total function calls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              ridder:   769536 total function calls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              bisect:  2146325 total function calls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Tried running and caught a bug.  \"TypeError: unsupported operand type(s) for +: 'int' and 'tuple'\" at line 43.  Noticed a rogue comma at the end of FUNCTIONS.  Also a rogue comma at the end of \"return optimizer(func, a, b, full_output=True[1].function_calls\".  Removed both."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Before running again, I decided to just walk through the code and knock out basic syntax errors.\n",
      "\u2022 Changed \"lambda x: x+np.sin(2*x)\" to \"lambda x: x+np.sin(2.0*x)\"\n",
      "\u2022 Changed \"lambda x: 1.1*x+np.sin(4*x)\" to \"lambda x: 1.1*x+np.sin(4.0*x)\"\n",
      "Now running again."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "OK, so some part of that solved the initial errors that I was having.  I'm getting some coherent output this time, but it's wrong.  \"brenth\" spits out the proper result.  However, the other ones are zero.  Why is that?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_a = -1.3 + np.random.random(size=100)\n",
      "random_b =   .3 + np.random.random(size=100)\n",
      "param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "print OPTIMIZERS[0].__name__, bench_optimizer(OPTIMIZERS[0], param_grid)\n",
      "print OPTIMIZERS[1].__name__, bench_optimizer(OPTIMIZERS[1], param_grid)\n",
      "print OPTIMIZERS[2].__name__, bench_optimizer(OPTIMIZERS[2], param_grid)\n",
      "print OPTIMIZERS[3].__name__, bench_optimizer(OPTIMIZERS[3], param_grid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "brenth "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "602858\n",
        "brentq 0\n",
        "ridder 0\n",
        "bisect 0\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "print OPTIMIZERS[0].__name__, bench_optimizer(OPTIMIZERS[0], param_grid)\n",
      "param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "print OPTIMIZERS[1].__name__, bench_optimizer(OPTIMIZERS[1], param_grid)\n",
      "param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "print OPTIMIZERS[2].__name__, bench_optimizer(OPTIMIZERS[2], param_grid)\n",
      "param_grid = product(FUNCTIONS, random_a, random_b)\n",
      "print OPTIMIZERS[3].__name__, bench_optimizer(OPTIMIZERS[3], param_grid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "brenth "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "602858\n",
        "brentq "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "591683\n",
        "ridder "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "772144\n",
        "bisect "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2147395\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Interesting.  When run one after another, it doesn't work the way that it should.  Why do I have to refresh that product each time?  Seeing that I have to do that now, why don't I just move the \"product\" into the \"for\" loop?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "OK so at this point, it runs without incident.  The numbers don't print out exactly as it was stated in the docstring, but it does print out.  My question now is, how much \"like\" the docstring is the output supposed to be?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}